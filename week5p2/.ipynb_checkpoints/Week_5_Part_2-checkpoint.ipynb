{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5 Part 2 Assignment\n",
    "### DATA 620\n",
    "\n",
    "David Moste ~ Euclid zhang ~ Samuel Reeves\n",
    "***\n",
    "### Problem Description\n",
    "\n",
    "Can we make a model with Python's Natural Language Toolkit that accurately categorizes real and fake news?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tarfile\n",
    "import io\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description & Preprocessing\n",
    "\n",
    "Data source: https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset\n",
    "\n",
    "This set contains just under 50k news items, about 55:45 fake:real.  We have downloaded the set and put in the github repository with lzma encryption so that it can be accessed simply from any machine.\n",
    "\n",
    "The important steps to transform this human-readable news into clean data are the following:\n",
    "\n",
    "1. Downloading and decompressing the csv data\n",
    "2. tokenizing the text bounded by whitespace\n",
    "3. removing numbers and special characters (except the period used for abbreviations)\n",
    "4. removing hyperlinks and artifacts of html\n",
    "5. removing stop words\n",
    "6. changing contractions to their long form (eg. he's --> he is)\n",
    "7. The string \"Images.\" at the end of the text, used to show that there are attached images\n",
    "8. stemming and lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_url = \"https://github.com/ezaccountz/Data_620/raw/main/week5p2/Fake.zip\"\n",
    "real_url = \"https://github.com/ezaccountz/Data_620/raw/main/week5p2/True.zip\"\n",
    "fake = requests.get(fake_url).content\n",
    "real = requests.get(real_url).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news = pd.read_csv(r\"Fake.csv\", header=0, index_col=False)\n",
    "real_news = pd.read_csv(r\"True.csv\", header=0, index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the column variable indicating the news is fake or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news['fake'] = True\n",
    "real_news['fake'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of fake news and number of real news:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fake_news), len(real_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are too many news items! we will select a small subset for our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, a set of news with category 'politices' and with Trump mentioned in the news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news2 = fake_news.loc[fake_news['subject'] == 'politics']\n",
    "real_news2 = real_news.loc[fake_news['subject'] == 'politics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news2 = fake_news2.loc[[bool(re.search('[t|T]rump',news)) for news in fake_news2['text']]]\n",
    "real_news2 = real_news2.loc[[bool(re.search('[t|T]rump',news)) for news in real_news2['text']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fake_news2), len(real_news2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the fake news and real news into one data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = fake_news2[['text','fake']].append(real_news2[['text','fake']], ignore_index = True)\n",
    "\n",
    "#complete list of all news\n",
    "#news = fake_news[['text','real_news']].append(real_news[['text','real_news']], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the first news and see what we should do to clean up the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create stemmer and lemmatizer. Generate a list of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "#add extra stop words that is not included in the stop words list\n",
    "#'' is used to remove empty word\n",
    "stop_words = stop_words + ['could', 'should','would','']\n",
    "#keep the word 'not' in the text since negation may have meanings here\n",
    "stop_words.remove('not')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a function to perform text cleaning as described above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    #convert to lower case\n",
    "    text = str(text).lower()   \n",
    "    \n",
    "    #remove hyperlinks\n",
    "    text = re.sub(r'[^\\s]+\\.com.[^\\s]+','',text)\n",
    "    text = re.sub(r'http[^\\s]+','',text)\n",
    "    \n",
    "    #clean the html markups\n",
    "    text = BeautifulSoup(text).get_text()\n",
    "    \n",
    "    #A lot of the news have the word 'images' at the end to represent that \n",
    "    #there are images attached to the news. We will remove such words\n",
    "    text = re.sub(r'Images\\.$', '', text)\n",
    "    \n",
    "    #remove special characters except '.', since it can be used in abbreviations (F.B.I. for example)\n",
    "    text = re.sub(r'[^A-Za-z\\s\\.]+', ' ', text)  \n",
    "    #remove '.' that is not used in abbreviations\n",
    "    text = re.sub(r'([A-Za-z]{2,})\\.', r'\\1 ', text)\n",
    "    \n",
    "    \n",
    "    #replace multiple spaces by 1 space\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)\n",
    "       \n",
    "    #in the text, the ' character is omiited. Therefore, string such as he's is stored as he s\n",
    "    #the following codes covert such string to its complete form. For example, he'll is coverted into he will\n",
    "    text = re.sub(r'(he|she|it|this|that) (s )', r'\\1 is', text)\n",
    "    text = re.sub(r'(they|we) (re)', r'\\1 are', text)\n",
    "    text = re.sub(' ve ', ' have ', text)\n",
    "    text = re.sub(' ll ', ' will ', text)\n",
    "    text = re.sub('won t ', 'will not ', text)\n",
    "    text = re.sub('n t ', ' not ', text)\n",
    "    \n",
    "    #split the text into words and filter out stop words\n",
    "    text = [word for word in text.split(' ') if word not in stop_words]\n",
    "    #text stemming\n",
    "    text = [porter.stem(word) for word in text]\n",
    "    #text lemmatizing\n",
    "    text = [wnl.lemmatize(word) for word in text]\n",
    "   \n",
    "    #convert the words back to one string\n",
    "    text = \" \".join(text)\n",
    "    #remove spaces from start and end of string\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up all texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "news['cleaned_text'] = news['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there are any documents with empty content after text clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news.loc[[len(news) == 0 for news in news['cleaned_text']]]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documents with only a hyper link as content will become an empty string after clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove documents with empty content after text clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = news.loc[[len(news) != 0 for news in news['cleaned_text']]]\n",
    "news.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#news.to_csv(r\"E:\\SPS\\DATA 620\\assignments\\data\\fake and real news\\news.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#news = pd.read_csv(r\"E:\\SPS\\DATA 620\\assignments\\data\\fake and real news\\news.csv\", header=0, index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use TfidfVectorizer to calculate the Term Frequency — Inverse Document Frequency of unigram tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tf_Idf_Vectorizer = TfidfVectorizer(ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Tf_Idf_Vectorizer.fit_transform(news['cleaned_text']).toarray()\n",
    "Y = news['fake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidfvect = pd.DataFrame(data = X,columns = Tf_Idf_Vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidfvect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the TF-IDF data frame into one with fake news and one with real news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidfvect_real = df_tfidfvect.loc[news['fake'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidfvect_fake = df_tfidfvect.loc[news['fake']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important key words mentioned in real news (excluding Trump since we selected our subset by the key word 'Trump') are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_important_real = df_tfidfvect_real.sum().sort_values(ascending = False).T.drop('trump')\n",
    "most_important_real[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordcloud\n",
    "from wordcloud import WordCloud\n",
    "Cloud = WordCloud(width=600, height=400, background_color=\"white\", max_words=50).generate_from_frequencies(most_important_real)\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.imshow(Cloud, interpolation ='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important key words mentioned in fake news (excluding Trump since we selected our subset by the key word 'Trump') are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_important_fake = df_tfidfvect_fake.sum().sort_values(ascending = False).T.drop('trump')\n",
    "most_important_fake[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordcloud\n",
    "from wordcloud import WordCloud\n",
    "Cloud = WordCloud(width=600, height=400, background_color=\"black\", max_words=50).generate_from_frequencies(most_important_fake)\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.imshow(Cloud, interpolation ='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting to see that a lot of key words about real news are about republicans and a lot of key words about fake news are democrats. The politics news are really politics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build our model using Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform cross validation and generate a list of performance scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = pd.DataFrame(columns = ['accurary','precision','recall','F1',\n",
    "                                       'True Positive','False Positive','True Negative','False Negative'])\n",
    "kf = KFold(n_splits=5,random_state=620,shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    mnb.fit(X_train, Y_train)\n",
    "    y_pred = mnb.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(Y_test, y_pred)\n",
    "    precision = metrics.precision_score(Y_test, y_pred)\n",
    "    recall = metrics.recall_score(Y_test, y_pred)\n",
    "    F1 = metrics.f1_score(Y_test, y_pred)\n",
    "    cm = metrics.confusion_matrix(Y_test, y_pred)\n",
    "    cm = cm/cm.astype(np.float).sum(axis=0)\n",
    "    model_scores.loc[len(model_scores)] = [accuracy,precision,recall,F1,cm[1, 1],cm[0, 1],cm[0, 0],cm[1, 0]]\n",
    "    \n",
    "model_scores.loc['Average'] = model_scores.mean()\n",
    "\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores are indicating that our model is performing well. The accurary is around 90 percent. We have correctly identified 87% of the fake news and 96% of the real news"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
